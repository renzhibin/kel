人大金仓数据卸载加载工具技术方案
一、引言
1.1 建设背景
为了减轻各项目组在数据入库过程中的开发和维护成本，避免因分散开发卸载、配置、数据交换模块导致的冗余建设和协作效率问题，需开发标准化的人大金仓卸载工具，实现技术组件的集中管控与流程规范化。
1.2 建设目标
构建一套标准化、高安全、可扩展的数据卸载与加载平台。解决现有各项目组重复开发脚本、安全标准不统一、非结构化文件落地困难等问题。系统核心能力包括:
数据卸载:将人大金仓数据库（结构化数据）和服务器文件（非结构化数据）安全、高效地卸载为本地加密数据包。
数据加载:将加密的卸载文件解密、校验后加载到目标数据库及文件系统,支持全量、增量及跨库传输。
非结构化文件处理:提供基于时间窗口的文件采集（加载）、传输和还原（卸载）。
二、系统总体架构
系统采用 管控中心-执行节点 模式，依赖xxl-job进行任务调度触发。系统核心组件如下：
管控中心 (Master)：负责任务配置、生成任务快照、任务状态监控。
执行节点 (Worker)：作为xxl-job执行器，接收调度中心的调用，执行数据卸载/加载/压缩/加密、本地落盘。
发送端：卸载 → 压缩(整体) → 分片（拆分）→ 摘要（分片） → 加密（分片）
接收端：解密（分片）→ 校验（分片）→ 合并（整体）→ 解压（整体）->卸载
数据库 (Database)：存储作业配置、执行日志等
三、核心模型设计
3.1 作业执行表设计 
这是管控与执行交互的核心表，用于存储所有任务的执行信息和状态。关键字段说明：
字段名	类型	说明
task_id	BIGINT	任务实例唯一ID（主键）
job_code	VARCHAR(64)	作业编码（如 bss、lcss）
batch_number	VARCHAR(64)	批次号（如 20260119020000_001）
node_name	VARCHAR(128)	执行该任务的节点名称
status	VARCHAR(32)	状态：RUNNING/SUCCESS/FAILED
config_snapshot	TEXT	任务配置快照，包含作业的完整配置快照，保证任务执行时配置的一致性
progress	INT	导出/压缩/加密
message	TEXT	日志摘要，执行节点在处理数据时，可定期更新任务的进度和状态描述
error_message	TEXT	错误信息（失败时记录）
create_time	TIMESTAMP	任务生成时间
start_time	TIMESTAMP	实际开始时间
end_time	TIMESTAMP	结束时间
3.2 配置文件模型设计
3.2.1 整体说明
系统采用 YAML 格式配置文件，分为全局配置和作业配置两层结构。单个卸载作业的执行时间建议不超过 2小时。如果数据量较大导致执行时间过长，建议拆分为多个作业或增加作业内并发度。全局配置：global.yaml，定义整体运行环境和约束条件。卸载作业配置：{作业名称}_extract.yaml（如 bss_extract.yaml），定义各业务系统的卸载配置。加载作业配置：{作业名称}_load.yaml（如 bss_load.yaml），定义各业务系统的加载配置。具体如下：
全局配置：由工具开发方维护，定义整体运行环境和约束条件，保存至入Nacos，典型包括：
目录与文件配置：工作目录（work_dir，数据处理过程中的临时工作空间，用于存放正在处理的数据文件数据处理过程中的工作空间）、交换目录（exchange_dir，最终交付的数据存放目录）、文件命名规则、批次号格式、文件编码、分隔符等
并发控制：默认作业内并发度（控制单个作业内并发抽取表的数量）
失败重试策略：最多重试次数、重试间隔（秒）
压缩与分片配置：压缩算法、分片阈值（GB）
安全配置：统一的 SM4 密钥、完整性校验与加密策略等
作业配置：由各项目组维护，是配置管理和调度管理中的基本对象，用于承载某一业务系统一组完整的卸载配置。典型包括：
基本属性与调度属性：
·作业标识、作业名称、作业描述
·作业类型（如 EXTRACT/LOAD）
·XXl-JOB配置：开始执行时间（如 02:00）
·XXl-JOB配置：执行日历规则（如每天、仅工作日、仅周末等）
数据源与目标配置：
·数据源信息：数据库主机地址、端口、数据库名、用户名、密码，版本，或源文件读取路径
·目标配置：目标端类型及连接/写入参数（如目标库、目标目录等）
·交换目录
抽取配置：
·抽取类型：全量（FULL）或增量（INCREMENTAL）
·全量抽取：配置表清单
·增量抽取：配置自定义 SQL 列表（支持按业务规则定义增量范围）
运行参数：
·作业内并发度（用于按需覆盖全局默认配置）
·失败重试次数与间隔（用于按需覆盖全局默认配置）
·加密密钥或加密开关（可选，用于在作业级覆盖全局安全策略）
目录配置说明：
系统涉及多个目录配置，按用途说明如下：
·work_dir：卸载时的临时工作空间，用于数据导出、打包、压缩等中间处理过程 ，全局配置（可被作业配置覆盖） 
·exchange_dir，卸载后的最终交付目录，存放完成加密的数据包，供数据传输使用  全局配置（可被作业配置覆盖） 
·extract_directory，文件卸载时的源文件路径，指定要采集的非结构化文件所在目录，文件卸载作业配置 
·input_directory，加载时的输入数据包路径，指定接收到的加密数据包所在位置  ，用于加载类型作业 
·target_directory，文件加载时的还原目标路径，指定非结构化文件要还原到的目标文件系统位置 ，文件加载作业配置 
3.2.2 全局配置示例（global.yaml）
concurrency:
  default_table_concurrency: 10      # 作业级默认并发
retry:
  max_retries: 3
  retry_interval_sec: 300
compression:
  algorithm: "gzip"
  split_threshold_gb: 3.5            # 分片编号3位：.001, .002...
enable_compression:true  # 是否启用加密，默认true
security:
  sm4_key: "your_sm4_key_here"
  enable_encryption: true  # 是否启用加密，默认true

extract:
  work_dir: "/mnt/bigdisk/DES/NSIT_SEND/csdata"
  batch_number_format: "{yyyyMMddHHmmss}_{seq}"
  encoding: "UTF-8"
  database_version: "V8R6"
  cleanup_work_dir: true 
 
3.2.3 卸载作业配置示例
数据库数据卸载示例（bss_extract_kingbase.yaml）
job:
  type: "EXTRACT_KINGBASE"
  name: "bss"
  description: "债券系统"
extract_database:
  host: "192.168.1.100"
  port: 54321
  name: "bssdb"
  user: "bss_user"
  password: "yourpassword"
version: "V8R6"
work_dir: "/mnt/bigdisk/DES/NSIT_SEND/csdata"
exchange_dir: "/mnt/bigdisk/DES/NSIT_SEND/csdata"  # 交换目录：最终交付的数据存放目录
extract_tasks: 
  - type: "FULL"
    tables:
      - t_bond_info
      - t_bond_trade
      - t_bond_position
      - t_settlement
    interface_mapping:                 # 可选，用于生成标准文件名
      t_bond_info: "J0001"
      t_bond_trade: "J0002"
  - type: "INCREMENTAL"
    sql_list:                          # 增量模式使用SQL列表
      - name: "company_info_inc"
         sql: |
          SELECT * FROM t_company_info 
          WHERE update_time >= CURRENT_DATE
      - name: "stock_trade_inc"
        sql: |
          SELECT * FROM t_stock_trade 
          WHERE trade_date = CURRENT_DATE
    interface_mapping:
      company_info_inc: "J0001"
      stock_trade_inc: "J0002"
runtime:
  table_concurrency: 1  #覆盖全局默认值

非结构化文件基于时间的文件卸载示例
job:
  type: "FILE_EXTRACT"
  name: "logs_extract"
  description: ""
extract_directory:"/app/xx/"  #需要抽取的非结构化文件目录
work_directory:”/xx/xx” # 工作目录，生成临时文件
extract_tasks:
  type: "INCREMENTAL"
  attribute:
      method: "TIME_BASED"                
      file_pattern: "*.pdf"  
      time_type: "MODIFY_TIME"
      time_range: "LAST_1_DAY"
      file_size_limit_mb: 500
3.2.4 加载作业配置示例
结构化数据加载示例（bss_load.yaml）
job:
  type: "KINGBASE_LOAD"
  name: "bss_load"
  description: "债券系统数据加载"
input_directory:"/mnt/data/received/bss/"  # 输入目录：从交换目录接收的数据包位置
target_database:
  host: "192.168.2.100"
  port: 54321
  name: ""
  user: "t_user"
  password: "yourpassword"
load_tasks:
- type: "TRUNCATE_LOAD"
    interface_mapping:
      - "J0001": "t_bond_info"
- "J0002": "t_bond_trade" 
- type: "MERGE "
  interface_mapping:
      - "t_bond_info": "t_bond_info_back"
  sql_list:                          # 增量模式使用SQL列表
      - name: "t_bond_info"
enable_transaction: true
        sql: |
     	DELETE FROM t_bond_trade
     	WHERE trade_id IN (SELECT trade_id FROM t_bond_info_back);
     	-- 将临时表数据插入到目标表
     	INSERT INTO t_bond_trade (trade_id, bond_id, trade_date, amount, price)
     	SELECT trade_id, bond_id, trade_date, amount, price
     	FROM t_bond_info_back;
runtime:
  table_concurrency: 8
非结构化文件加载示例（attachment_load.yaml）
job:
  type: "FILE_LOAD"
  name: "attachment_load"
  description: "附件系统"
input_directory:"/mnt/data/received/attachment/"
target_directory:"/xxx/xx"  #目标目录：文件还原到的目标路径
load_tasks:
  type: "APPEND"
runtime:
  table_concurrency: 1

3.3 数据交换标准与规范设计
本节定义数据包的协议标准，确保跨系统、跨网络环境的数据一致性。
3.3.1 批次号设计
批次号用于唯一标识一次作业级的数据卸载操作，并贯穿源端导出、数据交换和目标端。批次号组成规则，组成形式：{yyyyMMddHHmmss}_{当日序号}。示例：20260119020000_001。
字段含义：
·时间戳：精确到秒（yyyyMMddHHmmss），用于区分不同时间触发的卸载任务。
·当日序号：3位数字，第一次001，补数改为002，以此类推
生成逻辑：
·生成任务时，根据任务序列获取当日序号
3.3.2 文件命名规范（以接口规范和双方约定为准，以下为参考示例）
数据文件命名规则：
每个表生成一个独立的数据文件，保存到工作目录 {作业名称}/{批次号}/ 下。
文件命名格式遵循标准规范：[数据源英文缩写]_[接口标识]_[版本号]_[数据日期]_[当日序号]_[增量/全量标识].[文件扩展名]
命名规则说明：
字段	说明	来源/规则
[数据源英文缩写]	用于标识数据源机构的唯一代码，英文大写	作业名称（job_code）转换为大写
[接口标识]	表名或接口规范中约定的接口编号，用于唯一识别该数据源提供的具体接口。由1位的接口形态字符（J：结构化数据；F：非结构化数据）+4位数字或表名编码表示	J + 表名（如 J0001 或 {t_bond_info}）。支持通过配置表名到接口编号的映射关系，如t_bond_info → J0001`
[版本号]	接口标识版本号	3位字符，从V01至V99编号。除特殊约定外，默认为V01
[数据日期]	数据日期	8位数字，格式为YYYYMMDD，和批次号（yyyyMMddHHmmss格式）前8位一致
[当日序号]	用于一个传输内的数据分多批次传输的情况	3位数字，从批次号的当日序号部分提取（批次号当日序号为3位，直接使用）。第一次传送是001，第二次传送是002，以此类推。对于每传输期内只传送一次的接口，当日序号固定为001
[增量/全量标识]	标识传输的数据类型	1位字符：A（历史全量）、Q（当期全量）、Z（增量）。映射关系：FULL（全量抽取）→ Q，INCREMENTAL（增量抽取）→ Z。如果接口不区分增全量，则按Q填写
[文件扩展名]	文件格式	.TXT（固定）
文件命名示例：BSS_J0001_V01_20260119_001_Q.TXT，即：
数据源：BSS（债券系统）
接口标识：J0001（结构化数据，表t_bond_info对应的接口编号）
版本号：V01
数据日期：20260119
当日序号：001
增全量标识：Q（当期全量）
压缩包命名示例：
单文件压缩包：{作业名称}_{批次号}.tar.gz
分片压缩包：{作业名称}_{批次号}.tar.gz.001、{作业名称}_{批次号}.tar.gz.002、{作业名称}_{批次号}.tar.gz.003
清单文件命名规则：{作业名称}_{批次号}.manifest.json：记录文件清单、文件大小、摘要值、生成时间等信息
3.3.3 文件内容格式规范（以接口规范和双方约定为准，以下为参考示例）
数据文件内容格式规范：
规范项	说明
字符集	UTF-8
首行	文件首行不留空，无表头，无列名
数据行	每条记录一行，无空行
换行符	行尾以十六进制的 0x0A 结束。若字段内容中包含上述约定的换行符时，以 0x11 对其进行替换
数据列	字段间以特定的分隔符分隔，每条记录最后一个字段后无分隔符
列分隔符	字段间以十六进制 0x1E 为分隔符。若字段内容中包含上述约定的分隔符时，以 0x12 对其进行替换
NULL值	NULL字段用连续两个分隔符表示，不能省略
0值	0值，用0表示，不能用空格代替
字段顺序	需要严格按照每个接口约定顺序存放
压缩格式：
打包格式：tar
压缩算法：gzip
压缩后文件扩展名：.tar.gz
分片策略：
o当压缩前数据量较小，压缩后整体体积不超过分片阈值时，可生成单一压缩包
o当数据量较大、压缩后体积超过分片阈值（如 3.5GB）时，工具按阈值进行分片压缩，以保证每个压缩分片文件的体积不超过该阈值。分片编号统一为3位数字（.001, .002, .003...）
3.3.4 目录结构说明：
在打包压缩前，工作目录 {作业名称}/{批次号}/ 下的文件组织结构如下：
{作业名称}/{批次号}/
├── data/                                   #结构化数据文件（TXT/CSV）
│   ├── bss_01_20260119_001_Q.TXT          # 证券账户表数据
│   ├── bss_01_trade_20260119_001_Q.TXT            # 证券交易表数据
│   └── ...                                         # 其他表的数据文件
│
├── files/非结构化文件相对路径                            # 保持相对路径结构
│   │── pdf_001.pdf
│   │── word_002.docx
│   └── ...                                         # 其他非结构化文件
│
└── {作业名称}_{批次号}.manifest.json   #元数据文件

3.4.4 安全设计
为确保数据传输的机密性与完整性，将采用国密算法进行安全处理。
安全处理流程：
1.计算摘要：对压缩后的文件或分片使用 SM3 算法计算文件摘要值
2.加密处理：对压缩后的文件或分片使用 SM4 算法进行加密
3.生成清单：记录文件清单、文件大小、摘要值、生成时间等信息
解密与验证流程：
1.读取清单文件：读取并解析清单文件
2.数据解密：使用 SM4 算法解密各分片文件
3.摘要校验：对解密后的文件计算 SM3 摘要值，与清单中的摘要值比对，验证文件完整性
4.合并解压：合并分片文件并解压缩，得到原始 TXT数据文件和非结构化文件
完整性校验机制：
1.分片级别：每个分片计算独立的 SM3 摘要值，用于验证文件完整性
2.文件级别：非结构化文件使用 SM3 值进行校验
3.4.5 清单文件（manifest.json）规范
清单文件用于记录数据包的完整元数据信息，文件命名格式为：{系统名称}_{批次号}.manifest.json。
清单文件内容包括：
基本信息：
批次号（batch_number）
作业编码（job_code）
作业类型（job_type）：EXTRACT 或 LOAD
作业描述（job_description）
生成时间（create_time）
是否包含非结构化文件（has_unstructured_files）
文件列表信息：
每个文件的文件名、文件大小（字节）、SM3摘要值
压缩信息：
压缩算法：gzip
原始大小（MB）
压缩后大小（MB）
压缩率
结构化数据信息：
表数量
总记录数
各表的记录数明细
非结构化文件信息（如果包含）：
卸载方式（extract_method）
文件数量
总大小（MB）
文件类型统计（如 PDF/WORD，可预留 IMAGE 等类型）
文件列表
{
  "basic_info": {
    "batch_number": "20260119020000_001",
    "job_code": "BSS_001",
    "job_type": "EXTRACT",
    "job_description": "用户数据导出作业",
    "create_time": "2024-01-01 10:30:00",
    "has_unstructured_files": true
  },
  "file_list": [
    {
      "filename": "user_data_20240101.tar.gz.001",
      "size_bytes": 3758096384,
      "sm3_hash": "a1b2c3d4e5f6789012345678901234567890abcdef1234567890abcdef123456"
    }
  ],
  "compression_info": {
    "algorithm": "gzip",
    "original_size_mb": 10240.5,
    "compressed_size_mb": 6981.2,
    "compression_ratio": 0.68
  },
  "structured_data_info": {
    "table_count": 2,
    "total_records": 1200000,
    "table_details": [
      {
        "table_name": "t_secu_account",
        "record_count": 200000,
        "file_name": "t_secu_account_20240101.txt",
        "file_size_bytes": 20971520
      },
      {
        "table_name": "t_secu_trade",
        "record_count": 1000000,
        "file_name": "t_secu_trade_20240101.txt",
        "file_size_bytes": 104857600
      }
    ]
  },
  "unstructured_files_info": {
    "extract_method": "TABLE_RELATION",
    "file_count": 5000,
    "total_size_mb": 1024.5,
    "file_type_statistics": {
      "PDF": {
        "count": 3500,
        "size_mb": 750.0
      },
      "WORD": {
        "count": 1500,
        "size_mb": 274.5
      }
    }
"file_details": [
 "a.pdf" ,
xxxx
]
  }
}

四、核心业务流程
4.1 任务生成逻辑
1．XXL-JOB触发调度
2．将作业配置序列化为 JSON 格式，存入 config_snapshot 字段，生成任务记录
3．生成唯一的 batch_number（批次号），格式为 yyyyMMddHHmmss_当日序号
4．任务初始状态设置为 RUNNING，作业内部通过作业内并发度控制单个作业并发抽取的表数量。
4.2 数据处理模块
聚焦数据抽取、转换、卸载、加载、压缩、分片以及安全相关处理流程。支持卸载(EXTRACT)和加载(LOAD)两种作业类型。
4.2.1 初始化
Worker 解析配置快照，解析 config_snapshot ，初始化数据库连接池，创建目录等
4.2.2 数据卸载
结构化数据导出：
1．拼接 COPY (...) TO SQL 语句，支持全量表导出与自定义 SQL 导出。
全量导出：COPY table_name TO '/path/to/file.csv' WITH ...
自定义SQL导出：COPY (SELECT ...) TO '/path/to/file.csv' WITH ...
2．按表生成独立 TXT/CSV 文件，输出到工作目录 {work_dir}/{作业名称}/{批次号}/。
3．记录每个表的导出状态（成功/失败）、记录数、文件大小及文件路径等信息。
非结构化文件采集：
1．扫描根目录及文件匹配规则（如 /app/logs/*.log），递归扫描根目录 
2．按修改时间筛选 
3．复制文件到工作目录，同时保持相对路径结构以便后续还原，并记录相关元数据。

4.2.3 后处理流水线
1．校验：文件列表和配置一致性 ，文件可读性。
2．打包：以作业为粒度对工作目录进行文件汇聚成tar包。
3．压缩：使用 gzip 算法压缩 tar 包。追求速度可跳过压缩。
4．分片：若压缩后体积超过阈值，执行 split 拆分。
5．安全：摘要和加密
6．交付：将工作目录 {work_dir}/{作业名称}/{批次号}/ 的打包文件复制到交换目录 {exchange_dir}/{作业名称}/{批次号}/ 下，附加.tmp临时后缀，复制完成后去除后缀，更新状态为 SUCCESS。
4.3 数据加载执行流程 (Load)
4.3.1 解包与校验
1．读取清单文件。
2．安全解包：拒绝不完整或被篡改数据。
3．合并分片并解压，还原标准目录结构。
4.3.2 结构化数据加载
根据配置策略执行加载：
1．全量覆盖 (TRUNCATE_LOAD)：开启事务 -> TRUNCATE 目标表 -> COPY FROM 导入 -> 提交事务。
2．增量追加 (APPEND)：直接执行 COPY FROM 导入。
3．增量合并 (MERGE)：根据配置事务模式实现SQL，推荐写入临时表，delete+insert模式。
4.3.3 非结构化文件还原
1．读取 {作业名称}_{批次号}.manifest.json。
2．文件落地与完整性校验：将文件从 files/目录移动到目标绝对路径，自动创建缺失父目录，必要时保持文件的修改时间。
五、后台管理与异常处理
5.1 管理控制台后端接口设计
5.1.1 作业配置管理接口
负责作业元数据、数据源管理。
接口名称	请求方法	接口路径 (URL)	说明
作业列表查询	GET	/api/job/list	支持按类型、状态查询，返回作业概览。视需求增加权限控制功能
作业详情查询	GET	/api/job/{jobId}	获取作业完整配置（含数据源、调度等）
新建/保存作业	POST	/api/job/save	新增或更新作业配置
删除作业	DELETE	/api/job/{jobId}	逻辑删除
5.1.2 任务配置接口
负责结构化数据的表清单维护，以及非结构化文件的采集规则配置。
接口名称	请求方法	接口路径 (URL)	说明
表清单查询	GET	/api/config/tables	查询指定作业下的表配置列表
表配置批量保存	POST	/api/config/tables/batch	批量新增或更新表抽取策略（全量/增量SQL）
表清单导入	POST	/api/config/tables/import	解析上传的 Excel/CSV 文件并入库
数据源连接测试	POST	/api/config/tables/test-connection	传入数据源配置，返回连接测试结果及延迟
非结构化规则保存	POST	/api/config/files/save	时间扫描规则
文件采集预览	POST	/api/config/files/preview	预演接口：根据规则扫描源端，返回前 20 条文件样本，不执行实际下载
5.1.3 脚本执行与监控接口
负责任务生命周期的查询。
接口名称	请求方法	接口路径 (URL)	说明
任务列表查询	GET	/api/task/list	支持按批次号、状态、时间范围分页查询
任务详情查询	GET	/api/task/{taskId}/detail	获取任务各阶段（导出/压缩/加密）详细耗时与状态
脚本执行	POST 	/api/script/execute	执行自定义SQL脚本，支持单表操作、数据查询等
脚本执行历史 	GET 	/api/script/history	查询脚本执行历史记录
脚本执行结果    	GET 	/api/script/{executionId}/result	获取脚本执行结果和输出日志 
5.1.4 运维与统计接口
提供日志下载、报表统计及历史归档查询。
接口名称	请求方法	接口路径 (URL)	说明
日志摘要查询	GET	/api/log/{taskId}/summary	获取任务执行的关键节点日志（内存/数据库日志）
日志文件下载	GET	/api/log/{taskId}/download	下载完整的任务执行日志文件（.log）
清单文件查看	GET	/api/log/{taskId}/manifest	查看该批次的 manifest.json 内容
5.2 异常处理和容错机制
1．数据库连接异常：捕获 JDBC 异常,Worker需要重连机制，防止网络瞬断导致节点僵死。
2．任务失败重试配置 max_retries，并增加重试计数。
3．加载容错：单表错误，事务回滚，整体任务需继续进行。
4．磁盘水位保护：任务启动前及解压过程中，检查目标磁盘剩余空间。根据压缩包的大小判断若低于安全阈值，拒绝执行。
5.3 人工干预
1．任务重新启动：XXL-JOB启动任务
2．单表操作：管理后台提供脚本执行界面。  

六、代码结构
6.1 主要模块
系统打包为Jar运行于TongWeb容器中。主要模块如下：
·master：管控Web界面，负责任务配置和监控
·worker：执行节点，执行具体任务
·common：公共模块，配置加载、国密加解密、工具类
6.2 XXL-JOB任务注册
系统按作业类型注册多个JobHandler，每个作业配置对应一个XXL-JOB调度任务。
6.2.1 卸载作业Handler示例：
```java
@Component
public class ExtractJobHandler {
@Autowired
private JobConfigService jobConfigService;
@Autowired
private TaskExecutionService taskExecutionService;
/**
* 数据库卸载任务Handler
* 在XXL-JOB调度中心配置：BEAN模式，JobHandler=extractKingbaseHandler
*/
@XxlJob("extractKingbaseHandler")
public void extractKingbaseJob() {
// 1. 获取任务参数（作业编码通过XXL-JOB参数传递）
String jobParam = XxlJobHelper.getJobParam(); // 例如: {"jobCode":"bss"}
String jobCode = parseJobCode(jobParam);
// 2. 加载作业配置
JobConfig jobConfig = jobConfigService.loadJobConfig(jobCode);
// 3. 生成任务记录
Long taskId = createTaskRecord(jobCode, jobConfig);
// 4. 执行数据卸载
try {
TaskExecutionContext context = new TaskExecutionContext(taskId, jobConfig);
taskExecutionService.executeExtract(context);
// 5. 更新XXL-JOB执行日志
XxlJobHelper.log("任务执行成功，taskId={}", taskId);
XxlJobHelper.handleSuccess("SUCCESS");
} catch (Exception e) {
XxlJobHelper.log("任务执行失败：{}", e.getMessage());
XxlJobHelper.handleFail(e.getMessage());
throw e;
}
}
/**
* 文件卸载任务Handler
*/
@XxlJob("extractFileHandler")
public void extractFileJob() {
// 文件卸载逻辑（类似流程）
}
6.2.2 加载作业Handler示例：
```java
@Component
public class LoadJobHandler {
@Autowired
private TaskExecutionService taskExecutionService;
/**
* 数据库加载任务Handler
*/
@XxlJob("loadKingbaseHandler")
public void loadKingbaseJob() {
String jobParam = XxlJobHelper.getJobParam(); // {"jobCode":"bss_load","batchNumber":"20260119020000_001"}
try {
taskExecutionService.executeLoad(parseParam(jobParam));
XxlJobHelper.handleSuccess("SUCCESS");
} catch (Exception e) {
XxlJobHelper.handleFail(e.getMessage());
throw e;
}
}
/**
* 文件加载任务Handler
*/
@XxlJob("loadFileHandler")
public void loadFileJob() {
// 文件加载逻辑
}
}
```
6.3 XXL-JOB调度配置
在XXL-JOB调度中心Web界面配置任务：
| 配置项   | 示例值 | 说明 |
|-------  |--------|------|
| 执行器    | kdx-executor | application.yml中的appname |
| 任务描述   | BSS债券系统数据卸载 | 作业描述 |
| 调度类型   | CRON | 定时调度 |
| Cron表达式 | 0 0 2 * * ? | 每天凌晨2点执行 |
| 运行模式    | BEAN | Spring Bean模式 |
| JobHandler | extractKingbaseHandler |@XxlJob注解的value |
| 任务参数 | {"jobCode":"bss"} | JSON格式，传递作业编码 |
| 阻塞处理策略 | 单机串行 | 防止并发执行 |
6.4 任务执行流程伪代码
```java
// 任务执行主流程
class TaskExecutionService {
public void executeExtract(TaskExecutionContext context) {
Long taskId = context.getTaskId();
JobConfig config = context.getConfig();
try {
// 1. 初始化：解析配置快照，创建工作目录
init(config);
// 2. 数据卸载
if (config.hasStructuredData()) {
extractStructuredData(config); // 数据库导出
}
if (config.hasUnstructuredFiles()) {
extractUnstructuredFiles(config); // 文件采集
}
// 3. 后处理流水线
validateFiles(config); // 校验
compress(config); // 打包压缩
split(config); // 分片
encrypt(config); // 加密
generateManifest(config); // 生成清单
// 4. 交付与清理
moveToOutputDir(config);
cleanup(config);
// 5. 更新任务状态
updateTaskStatus(taskId, TaskStatus.SUCCESS);
} catch (Exception e) {
updateTaskStatus(taskId, TaskStatus.FAILED, e.getMessage());
throw new TaskExecutionException("任务执行失败", e);
}
}
// 数据库卸载
private void extractStructuredData(JobConfig config) {
List<ExtractTask> tasks = config.getExtractTasks();
// 根据作业内并发度并发执行
ExecutorService executor = Executors.newFixedThreadPool(
config.getTableConcurrency()
);
for (ExtractTask task : tasks) {
if (task.getType() == ExtractType.FULL) {
// 全量导出
for (String tableName : task.getTables()) {
executor.submit(() -> exportTable(tableName, config));
}
} else if (task.getType() == ExtractType.INCREMENTAL) {
// 增量导出（自定义SQL）
for (SqlConfig sql : task.getSqlList()) {
executor.submit(() -> exportBySql(sql, config));
}
}
}
executor.shutdown();
executor.awaitTermination(2, TimeUnit.HOURS);
}
// 表级导出
private void exportTable(String tableName, JobConfig config) {
String outputFile = buildOutputFilePath(tableName, config);
String copySql = String.format(
"COPY %s TO '%s' WITH (FORMAT CSV, DELIMITER E'\\x1E', ...)",
tableName, outputFile
);
jdbcTemplate.execute(copySql);
// 记录导出元数据
recordExportMetadata(tableName, outputFile);
}
}
```
6.5 任务监控与日志
系统日志分为两层：
XXL-JOB层日志，通过XXL-JOB调度中心查看任务触发时间、执行耗时、执行结果。
业务层日志，通过管控中心Web界面查看。详细的数据处理日志（表级进度、文件清单等）存储在数据库的task_execution表。
```java
// 业务日志记录示例
@Component
public class TaskLogger {
public void logProgress(Long taskId, String phase, int progress, String message) {
// 1. 更新数据库
taskDao.updateProgress(taskId, progress, message);
// 2. 输出到XXL-JOB日志
XxlJobHelper.log("[{}] progress={}, message={}", phase, progress, message);
}
}
```
6.5.作业配置加载
```java
@Service
public class JobConfigService {
@Autowired
private JobConfigDao jobConfigDao;
@Autowired
private GlobalConfigService globalConfigService;
/**
* 加载作业配置（合并全局配置和作业配置）
*/
public JobConfig loadJobConfig(String jobCode) {
// 1. 加载全局配置
GlobalConfig globalConfig = globalConfigService.load();
// 2. 加载作业配置
JobConfig jobConfig = jobConfigDao.findByJobCode(jobCode);
// 3. 合并配置（作业配置覆盖全局配置）
return mergeConfig(globalConfig, jobConfig);
}
}
```

七、项目风险
·技术风险：执行原生COPY 命令需执行机器部署 KSQL。若无法部署，需采用 COPY 重定向方式，会有性能下降问题。
·进度风险：春节假期人员请假，需提前安排相关工作。