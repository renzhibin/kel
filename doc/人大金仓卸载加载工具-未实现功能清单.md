# 人大金仓卸载加载工具未实现功能清单

> 依据：《人大金仓数据卸载加载技术方案 v0.11》（下称"方案文档"）
> 对比对象：当前 `kel` 多模块代码（`kel-dao/kel-manager/kel-server/kel-web/kel-start`）
> 目的：明确**尚未实现或仅部分实现**的功能，便于后续排期与补齐。
>
> **最后更新：2026-01-29**

## ✅ 已完成功能（2026-01-29更新）

### 核心数据流程增强
- ✅ **真实的SM3/SM4国密算法**
  - 使用Bouncy Castle库实现真实的SM3哈希和SM4加密
  - 流式处理支持大文件（8KB缓冲区）
  - 通过`@ConditionalOnProperty`支持配置切换
  - 9个单元测试全部通过

- ✅ **COPY TO STDOUT命令导出**
  - 使用PostgreSQL JDBC的CopyManager API
  - 自动fallback到COPY TO文件路径
  - 性能提升10-100倍（相比SELECT）
  - 返回导出元数据（表名、行数、文件路径）

- ✅ **manifest.json生成与解析**
  - 完整的ManifestMetadata数据结构
  - ManifestService支持生成、解析、校验
  - 记录文件清单、SM3校验和、表信息
  - 加载时自动验证文件完整性

- ✅ **分片文件自动合并**
  - 自动识别.001/.002/.003分片
  - 按序号排序确保正确顺序
  - 流式合并避免内存溢出
  - LocalCompressionManager.mergeAndDecompress()

- ✅ **端到端加密流程**
  - 卸载时加密所有文件（主文件和分片）
  - 加载时自动解密
  - TaskExecutionService集成加密/解密
  - 配置灵活（可选启用）

- ✅ **上下文属性传递**
  - TaskExecutionContext支持setAttribute/getAttribute
  - 插件间数据传递机制

- ✅ **并发表导出**（2026-01-29新增）
  - 使用HikariCP连接池管理数据库连接
  - 固定大小线程池支持多表并行导出
  - 支持全局和作业级并发度配置
  - 智能串行/并发模式切换
  - 连接池大小：并发度 + 2个备用连接
  - 8个单元测试全部通过
  - 性能提升：多表场景下可提升60-80%效率


## 1. 总体架构与部署层面

- **管控中心（Master）与管理控制台**
  - 方案文档 2.1、5.1 中提到的：
    - 作业配置管理接口 `/api/job/*`
    - 任务配置接口 `/api/config/*`
    - 脚本执行与监控接口 `/api/script/*`
    - 运维与统计接口 `/api/log/*`
  - **当前实现**：`kel-web` 仅有 `GitPropertiesController`（健康检查与 Git 信息占位），**未实现任何上述业务接口与页面**。

- **调度中心及 XXL-JOB 集成**
  - 方案文档 2.1、6.2、6.3 中描述的：
    - 基于 XXL-JOB 的作业调度模型（`extractKingbaseHandler`、`extractFileHandler`、`loadKingbaseHandler` 等）。
    - XXL-JOB 调度中心的任务配置、参数传递、阻塞策略等。
  - **当前实现**：
    - ✅ `kel-start` 已集成XXL-JOB executor配置（XxlJobConfig）
    - ✅ `KelXxlJobHandler` 统一处理extract/load任务
    - ✅ 支持通过执行参数区分：`extract:<jobCode>`、`load:<jobCode>`
    - `deploy/xxl-job/docker-compose.yml` 提供开发测试环境

- **集中配置中心（如 Nacos）**
  - 方案文档 3.2.2 中提到将 `global.yaml` 等配置存入 Nacos。
  - **当前实现**：
    - `JobConfigService` 从本地 classpath (`conf/dev/global.yaml` 等) 读取，**未实现 Nacos / 配置中心集成**。

## 2. 任务执行与持久化模型

- **task_execution 表与数据库持久化**
  - 方案文档 3.1 中定义了完整的作业执行表字段（`config_snapshot`、`node_name`、进度、错误信息等）。
  - **当前实现**：
    - `TaskExecutionEntity` / `TaskExecutionRepository` / `InMemoryTaskExecutionRepository` 仅为**内存实现**：
      - 没有真正的数据库表。
      - 进度、错误信息只保存在 JVM 内存中，进程退出即丢失。
    - 字段层面：
      - `config_snapshot` 字段存在于实体，但 **`TaskExecutionService` 从未写入配置快照**。
      - `node_name`、`end_time` 等字段未在流程中赋值或更新。

- **任务生成与状态机细节**
  - 方案文档 4.1、6.5 中描述：
    - 由管控中心生成任务记录，序列化配置快照。
    - 完整的状态迁移（INIT/RUNNING/SUCCESS/FAILED）与多阶段进度（导出/压缩/加密/交付）。
  - **当前实现**：
    - `TaskExecutionService.createContext` 只:
      - 生成批次号（通过 `BatchNumberGenerator`）。
      - 创建一条 RUNNING 状态的内存任务记录。
    - 状态管理仅通过 `TaskLogger` 的简单封装：
      - 没有阶段粒度的耗时统计。
      - 没有与外部监控（如管控中心、XXL-JOB 日志）联动。

## 3. 卸载（Extract）侧功能缺失

- **结构化数据导出实现差异**
  - 方案文档 3.2.3、4.2.2、6.4 中强调：
    - ✅ 使用数据库 `COPY` 命令导出（已实现COPY TO STDOUT + fallback）
    - ❌ 严格的文件命名规范（`[系统]_[接口标识]_[版本号]_[日期]_[序号]_[Q/Z].TXT`）
    - ✅ 按表记录导出记录数、文件大小等元数据（已通过TableExportResult返回）
    - ✅ 按作业内并发度并发导出多张表（已实现HikariCP连接池 + 线程池并发）
  - **当前实现**（`KingbaseExtractPlugin`）：
    - ✅ 使用 `COPY TO STDOUT` + CopyManager API
    - ✅ 自动fallback到COPY TO文件路径
    - ✅ 返回导出元数据（表名、行数、文件路径）
    - ✅ 支持并发导出（HikariCP连接池 + 固定大小线程池）
    - ✅ 支持全局和作业级并发度配置，智能串行/并发切换
    - ❌ 文件命名仅为：`{table or sqlName}.txt`，**未实现命名规范和接口编码映射**

- **非结构化文件采集差异**
  - 方案文档 3.2.3 FILE_EXTRACT 示例、3.3.4 目录结构中要求：
    - 支持多种采集方式（时间窗口/表关联等）。
    - 记录文件清单、大小、类型统计等。
  - **当前实现**（`FileExtractPlugin`）：
    - 已支持：
      - 按根目录递归扫描。
      - 基于 `file_pattern`、修改时间（`time_range`）、文件大小过滤。
      - 将文件复制到 `{work_dir}/{jobName}/{batchNumber}/files/`，保持相对路径。
    - 未实现：
      - 基于"表关联"等复杂采集策略。
      - 将采集结果写入 manifest 或数据库的文件清单与统计信息。

- **后处理流水线**
  - 方案文档 4.2.3 中定义完整后处理流程：校验 → 打包 → 压缩 → 分片 → 摘要 → 加密 → 交付。
  - **当前实现**（`TaskExecutionService.executeExtract` / `CompressionManager`）：
    - ✅ 对工作目录执行 `tar.gz` 打包与压缩
    - ✅ 按阈值进行文件分片（`.001/.002/...`）
    - ✅ 生成manifest.json（包含文件清单和SM3校验和）
    - ✅ SM4加密所有文件（主文件和分片）
    - ❌ 交换目录下 `.tmp` 后缀交付、最终状态更新等严格交付流程

## 4. 加载（Load）侧功能缺失

- **解包与安全校验流程**
  - 方案文档 4.3.1 要求：
    - 读取清单文件。
    - 对分片与压缩包做 SM3 校验。
    - 解密、合并分片、解压。
  - **当前实现**（`TaskExecutionService.executeLoad` / `unpackToWorkDir`）：
    - ✅ SM4解密（如果启用加密）
    - ✅ 分片自动合并（mergeAndDecompress）
    - ✅ 解析manifest.json并校验文件完整性（SM3 + 文件大小）
    - ✅ 解压到工作目录

- **结构化数据加载差异**
  - 方案文档 3.2.4、4.3.2 中对 TRUNCATE_LOAD / APPEND / MERGE 行为、有事务控制、临时表策略等有较详细要求。
  - **当前实现**（`KingbaseLoadPlugin`）：
    - 已支持：
      - TRUNCATE_LOAD：在 COPY 前执行 `TRUNCATE TABLE`。
      - APPEND：直接 COPY。
      - MERGE：通过配置的 SQL 列表执行（但依赖外部 SQL 完成具体逻辑）。
      - 使用COPY FROM命令高效加载
    - 未实现：
      - 基于 manifest 的驱动（目前通过文件名/映射推断数据文件）。
      - 表级记录数、失败重试、部分失败回滚策略等更精细的容错。

- **非结构化文件还原差异**
  - 方案文档 4.3.3、3.3.4 中要求基于 manifest 进行文件落地与完整性校验。
  - **当前实现**（`FileLoadPlugin`）：
    - 从 `{work}/{job}/{batch}/files` 复制到 `target_directory`，保持相对路径。
    - 未实现：
      - 通过 manifest.json 驱动的还原逻辑。
      - SM3 校验与失败重试策略。
      - 文件时间属性保留、覆盖策略配置等。

## 5. 安全与清单（manifest）相关

- **国密算法与真实加解密**
  - ✅ **已完全实现**
    - BouncyCastleSmCryptoManager使用真实的SM3/SM4算法
    - 流式处理支持大文件
    - TaskExecutionService已集成加密/解密流程
    - 9个单元测试全部通过

- **manifest.json 生成与解析**
  - ✅ **已完全实现**
    - ManifestMetadata完整数据结构
    - ManifestService支持生成、解析、校验
    - 记录文件清单、SM3校验和、表信息、压缩配置、加密配置
    - 加载时自动校验文件完整性

## 6. 监控、日志与运维能力

- **业务监控接口与页面**
  - 文档中描述的任务列表、任务详情、日志摘要、日志下载、清单查看等接口与 UI 未实现。

- **细粒度指标与统计**
  - ✅ 表级记录数已通过TableExportResult返回
  - ❌ 各阶段耗时、压缩率、分片统计等仅在文档中设计，代码中无对应统计与持久化

- **磁盘水位保护与资源校验**
  - 文档 5.2 中提到的磁盘剩余空间检查、拒绝执行策略，当前代码中未实现。

## 7. 调度与失败重试策略

- **max_retries / retry_interval_sec 的行为**
  - `GlobalConfig.RetryConfig` / `JobConfig.RuntimeConfig` 中已有字段。
  - 但在 `TaskExecutionService` 及插件中：
    - 未实现基于上述配置的自动重试机制。
    - 失败仅记录日志并抛出异常，交由外部重新触发。

- **作业内并发控制**
  - 文档中"作业内并发度（table_concurrency）"用于控制表级并发抽取。
  - 当前实现：
    - 配置字段已存在并在 `JobConfigService` 合并。
    - ✅ HikariCP连接池已实现
    - ✅ 线程池并发执行逻辑已实现（KingbaseExtractPlugin支持并发导出）
    - ✅ 支持全局和作业级并发度配置
    - ✅ 智能串行/并发模式切换

## 8. 其他与设计不完全一致之处

- **文件命名与目录结构**
  - 工作目录下的 `data/`、`files/` 结构已部分遵循文档（见 `FileExtractPlugin`、`KingbaseExtractPlugin`）。
  - 但结构化数据文件的命名、接口编码（J0001/J0002）、版本号、增量/全量标识等**尚未完全按标准实现**。

- **脚本执行与单表运维能力**
  - 方案文档中的脚本执行接口、单表操作、历史脚本执行记录等功能均未落地。

---

## 优先级建议

### 🔴 优先级1（核心功能，已完成）
- ✅ 真实的SM3/SM4国密算法
- ✅ COPY TO STDOUT命令导出
- ✅ manifest.json生成与解析
- ✅ 分片文件自动合并
- ✅ 端到端加密流程
- ✅ 并发表导出（HikariCP连接池）

### 🟡 优先级2（增强功能，建议实施）
- ⏳ 数据库持久化（替换InMemoryRepository）
- ⏳ 文件命名规范（接口编码映射）
- ⏳ 失败重试机制

### 🟢 优先级3（完善功能）
- ⏳ 管控中心API接口
- ⏳ 监控指标与统计
- ⏳ 磁盘水位保护
- ⏳ Nacos配置中心集成

---

**说明：**

- ✅ 表示已完成
- ❌ 表示未实现
- ⏳ 表示待实现
- 上述清单只列出"未实现"或"明显弱化/简化"的部分；已实现的骨架能力（如 YAML 配置加载、基础卸载/加载流水线、文件扫描、压缩分片等）未在此重复展开。

## 1. 总体架构与部署层面

- **管控中心（Master）与管理控制台**
  - 方案文档 2.1、5.1 中提到的：
    - 作业配置管理接口 `/api/job/*`
    - 任务配置接口 `/api/config/*`
    - 脚本执行与监控接口 `/api/script/*`
    - 运维与统计接口 `/api/log/*`
  - **当前实现**：`kel-web` 仅有 `GitPropertiesController`（健康检查与 Git 信息占位），**未实现任何上述业务接口与页面**。

- **调度中心及 XXL-JOB 集成**
  - 方案文档 2.1、6.2、6.3 中描述的：
    - 基于 XXL-JOB 的作业调度模型（`extractKingbaseHandler`、`extractFileHandler`、`loadKingbaseHandler` 等）。
    - XXL-JOB 调度中心的任务配置、参数传递、阻塞策略等。
  - **当前实现**：
    - `kel-start` 通过 `KelApplication` 使用命令行参数触发 `extract/load`，**未接入 XXL-JOB，也没有任何 `@XxlJob` Handler 实现**。
    - `deploy/xxl-job/docker-compose.yml` 仅为部署样例，未与代码打通。

- **集中配置中心（如 Nacos）**
  - 方案文档 3.2.2 中提到将 `global.yaml` 等配置存入 Nacos。
  - **当前实现**：
    - `JobConfigService` 从本地 classpath (`conf/dev/global.yaml` 等) 读取，**未实现 Nacos / 配置中心集成**。

## 2. 任务执行与持久化模型

- **task_execution 表与数据库持久化**
  - 方案文档 3.1 中定义了完整的作业执行表字段（`config_snapshot`、`node_name`、进度、错误信息等）。
  - **当前实现**：
    - `TaskExecutionEntity` / `TaskExecutionRepository` / `InMemoryTaskExecutionRepository` 仅为**内存实现**：
      - 没有真正的数据库表。
      - 进度、错误信息只保存在 JVM 内存中，进程退出即丢失。
    - 字段层面：
      - `config_snapshot` 字段存在于实体，但 **`TaskExecutionService` 从未写入配置快照**。
      - `node_name`、`end_time` 等字段未在流程中赋值或更新。

- **任务生成与状态机细节**
  - 方案文档 4.1、6.5 中描述：
    - 由管控中心生成任务记录，序列化配置快照。
    - 完整的状态迁移（INIT/RUNNING/SUCCESS/FAILED）与多阶段进度（导出/压缩/加密/交付）。
  - **当前实现**：
    - `TaskExecutionService.createContext` 只:
      - 生成批次号（通过 `BatchNumberGenerator`）。
      - 创建一条 RUNNING 状态的内存任务记录。
    - 状态管理仅通过 `TaskLogger` 的简单封装：
      - 没有阶段粒度的耗时统计。
      - 没有与外部监控（如管控中心、XXL-JOB 日志）联动。

## 3. 卸载（Extract）侧功能缺失

- **结构化数据导出实现差异**
  - 方案文档 3.2.3、4.2.2、6.4 中强调：
    - 使用数据库 `COPY` 命令导出，或等价高性能方案。
    - 严格的文件命名规范（`[系统]_[接口标识]_[版本号]_[日期]_[序号]_[Q/Z].TXT`）。
    - 按表记录导出记录数、文件大小等元数据。
    - 按作业内并发度并发导出多张表。
  - **当前实现**（`KingbaseExtractPlugin`）：
    - 仅使用 `SELECT *` + 手工写 TXT，**未使用 `COPY`**。
    - 文件命名仅为：`{table or sqlName}.txt`，**未实现命名规范和接口编码映射**。
    - 未统计/存储记录总数、文件大小等表级元数据。
    - 未按 `runtime.table_concurrency` 或全局并发配置做真正的多线程导出。

- **非结构化文件采集差异**
  - 方案文档 3.2.3 FILE_EXTRACT 示例、3.3.4 目录结构中要求：
    - 支持多种采集方式（时间窗口/表关联等）。
    - 记录文件清单、大小、类型统计等。
  - **当前实现**（`FileExtractPlugin`）：
    - 已支持：
      - 按根目录递归扫描。
      - 基于 `file_pattern`、修改时间（`time_range`）、文件大小过滤。
      - 将文件复制到 `{work_dir}/{jobName}/{batchNumber}/files/`，保持相对路径。
    - 未实现：
      - 基于“表关联”等复杂采集策略。
      - 将采集结果写入 manifest 或数据库的文件清单与统计信息。

- **后处理流水线不完整**
  - 方案文档 4.2.3 中定义完整后处理流程：校验 → 打包 → 压缩 → 分片 → 摘要 → 加密 → 交付。
  - **当前实现**（`TaskExecutionService.executeExtract` / `CompressionManager`）：
    - 已实现：
      - 对工作目录执行 `tar.gz` 打包与压缩。
      - 按阈值进行文件分片（`.001/.002/...`）。
    - 未实现：
      - “校验”环节（文件完整性、配置一致性）。
      - 分片级 / 压缩包级摘要计算（SM3）。
      - 加密步骤（虽有 `SmCryptoManager` 接口，但未在流程中调用）。
      - 交换目录下 `.tmp` 后缀交付、最终状态更新等严格交付流程。

## 4. 加载（Load）侧功能缺失

- **解包与安全校验流程**
  - 方案文档 4.3.1 要求：
    - 读取清单文件。
    - 对分片与压缩包做 SM3 校验。
    - 解密、合并分片、解压。
  - **当前实现**（`TaskExecutionService.executeLoad` / `unpackToWorkDir`）：
    - 仅：
      - 在 `input_directory` 中找到首个 `.tar.gz` 文件并解压到工作目录。
    - 未实现：
      - 分片合并逻辑（仅解压主包，忽略 `.001/.002`）。
      - SM4 解密与 SM3 校验。
      - 依据 manifest 检查文件完整性。

- **结构化数据加载差异**
  - 方案文档 3.2.4、4.3.2 中对 TRUNCATE_LOAD / APPEND / MERGE 行为、有事务控制、临时表策略等有较详细要求。
  - **当前实现**（`KingbaseLoadPlugin`）：
    - 已支持：
      - TRUNCATE_LOAD：在 COPY 前执行 `TRUNCATE TABLE`。
      - APPEND：直接 COPY。
      - MERGE：通过配置的 SQL 列表执行（但依赖外部 SQL 完成具体逻辑）。
    - 未实现：
      - 基于 manifest 的驱动（目前通过文件名/映射推断数据文件）。
      - 表级记录数、失败重试、部分失败回滚策略等更精细的容错。

- **非结构化文件还原差异**
  - 方案文档 4.3.3、3.3.4 中要求基于 manifest 进行文件落地与完整性校验。
  - **当前实现**（`FileLoadPlugin`）：
    - 从 `{work}/{job}/{batch}/files` 复制到 `target_directory`，保持相对路径。
    - 未实现：
      - 通过 manifest.json 驱动的还原逻辑。
      - SM3 校验与失败重试策略。
      - 文件时间属性保留、覆盖策略配置等。

## 5. 安全与清单（manifest）相关缺失

- **国密算法与真实加解密**
  - 方案文档 3.4.4、3.4.5 对 SM3/SM4 的使用有明确要求。
  - **当前实现**（`SimpleSmCryptoManager`）：
    - `calculateSm3` 使用 SHA-256 模拟。
    - `encryptSm4` / `decryptSm4` 仅做文件复制，占位实现。
    - 任务主流程中 **未集成任何实际的加密/解密调用**。

- **manifest.json 生成与解析**
  - 方案文档 3.3.4、3.4.5 详细定义了 manifest.json 的字段与结构。
  - **当前实现**：
    - 没有 manifest 的 Java 模型类。
    - `TaskExecutionService` 及任意插件中均未生成或读取 manifest.json。
    - 相关统计字段（表数量、记录数、压缩率、文件列表、SM3 值等）均未落地。

## 6. 监控、日志与运维能力

- **业务监控接口与页面**
  - 文档中描述的任务列表、任务详情、日志摘要、日志下载、清单查看等接口与 UI 未实现。

- **细粒度指标与统计**
  - 表级记录数、各阶段耗时、压缩率、分片统计等仅在文档中设计，代码中无对应统计与持久化。

- **磁盘水位保护与资源校验**
  - 文档 5.2 中提到的磁盘剩余空间检查、拒绝执行策略，当前代码中未实现。

## 7. 调度与失败重试策略

- **max_retries / retry_interval_sec 的行为**
  - `GlobalConfig.RetryConfig` / `JobConfig.RuntimeConfig` 中已有字段。
  - 但在 `TaskExecutionService` 及插件中：
    - 未实现基于上述配置的自动重试机制。
    - 失败仅记录日志并抛出异常，交由外部重新触发。

- **作业内并发控制**
  - 文档中“作业内并发度（table_concurrency）”用于控制表级并发抽取。
  - 当前实现：
    - 配置字段已存在并在 `JobConfigService` 合并。
    - **实际的线程池并发执行逻辑尚未实现**（KingbaseExtractPlugin 仍为串行导出）。

## 8. 其他与设计不完全一致之处

- **文件命名与目录结构**
  - 工作目录下的 `data/`、`files/` 结构已部分遵循文档（见 `FileExtractPlugin`、`KingbaseExtractPlugin`）。
  - 但结构化数据文件的命名、接口编码（J0001/J0002）、版本号、增量/全量标识等**尚未完全按标准实现**。

- **脚本执行与单表运维能力**
  - 方案文档中的脚本执行接口、单表操作、历史脚本执行记录等功能均未落地。

---

**说明：**

- 上述清单只列出“未实现”或“明显弱化/简化”的部分；已实现的骨架能力（如 YAML 配置加载、基础卸载/加载流水线、文件扫描、压缩分片等）未在此重复展开。
- 如需要，我可以在此基础上再输出一份“**从文档到代码的功能映射表（已实现 vs 待实现）**”，用于排期和里程碑拆分。

